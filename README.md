# üìä PR√ÅCTICA 3: IMPLEMENTACI√ìN Y EVALUACI√ìN DE NA√èVE BAYES
## Tecnolog√≠as de Lenguaje Natural

**Autor:** Escamilla Lazcano Sa√∫l
**Carrera:** Ingenier√≠a En Inteligencia Artificial

[![Python](https://img.shields.io/badge/Python-3.x-blue.svg)](https://www.python.org/)
[![Pandas](https://img.shields.io/badge/Librer√≠a-Pandas-purple.svg)](https://pandas.pydata.org/)
[![spaCy](https://img.shields.io/badge/Librer√≠a-spaCy-blue.svg)](https://spacy.io/)
[![NLTK](https://img.shields.io/badge/Librer√≠a-NLTK-green.svg)](https://www.nltk.org/)
[![Scikit-learn](https://img.shields.io/badge/Librer√≠a-Scikit--learn-orange.svg)](https://scikit-learn.org/)
[![Seaborn](https://img.shields.io/badge/Librer√≠a-Seaborn%20%7C%20Matplotlib-blueviolet.svg)](https://seaborn.pydata.org/)

## üöÄ Descripci√≥n del Proyecto

Este proyecto es una implementaci√≥n completa del algoritmo clasificador **Bayesiano Ingenuo (Na√Øve Bayes)** **desde cero** en Python. El objetivo es construir un modelo de **An√°lisis de Sentimiento** capaz de clasificar rese√±as de pel√≠culas como "positivas" o "negativas" bas√°ndose √∫nicamente en su contenido textual.

El *pipeline* del proyecto cubre todos los pasos esenciales de una tarea de PLN:
1.  **Carga y Exploraci√≥n de Datos** del dataset IMDB.
2.  **Preprocesamiento y Normalizaci√≥n de Texto** avanzado usando `spaCy` y `NLTK`.
3.  **Implementaci√≥n del Modelo** (`NaiveBayesPersonalizado`) desde cero.
4.  **Entrenamiento y Evaluaci√≥n** del modelo con m√©tricas de clasificaci√≥n est√°ndar.
5.  **Visualizaci√≥n de Resultados**, incluyendo una matriz de confusi√≥n y nubes de palabras.

## üíæ 1. Dataset

Se utiliza el **"IMDB Dataset of 50K Movie Reviews"**. Este es un corpus can√≥nico para tareas de clasificaci√≥n binaria de sentimiento.
* **Archivo:** `IMDB Dataset.csv`
* **Tama√±o:** 50,000 rese√±as.
* **Clases:** "positiva" (25,000) y "negativa" (25,000).

## ‚öôÔ∏è 2. Pipeline de Preprocesamiento de Texto

Para que el modelo pueda "entender" el texto, este debe ser normalizado. Se implement√≥ un pipeline robusto que seleccion√≥ la **Lematizaci√≥n (con `spaCy`)** sobre el *Stemming* (con `NLTK`), ya que la lematizaci√≥n produce palabras l√©xicamente correctas (lemas), lo cual es m√°s preciso.

El pipeline de normalizaci√≥n (`lematizar_texto`) realiza los siguientes pasos:
1.  **Conversi√≥n a Min√∫sculas:** `texto.lower()`
2.  **Eliminaci√≥n de HTML:** Se utiliza `re` para eliminar etiquetas (ej. `<br />`).
3.  **Tokenizaci√≥n (spaCy):** Se procesa el texto con el modelo `en_core_web_sm`.
4.  **Filtrado de Tokens:** Se eliminan *stopwords*, puntuaci√≥n y espacios.
5.  **Lematizaci√≥n (spaCy):** Cada token se reduce a su forma base de diccionario (ej. "running" ‚Üí "run").

## üß† 3. Implementaci√≥n del Modelo: `NaiveBayesPersonalizado` (Desde Cero)

El n√∫cleo de la pr√°ctica es esta clase, que no utiliza las implementaciones de `sklearn` para el clasificador.

### A. Entrenamiento (`fit`)
El m√©todo `fit` aprende las probabilidades necesarias del corpus de entrenamiento (`X_train`, `y_train`).

**1. C√°lculo de Priors de Clase $P(c)$:**
Calcula la probabilidad base de cada clase (positiva o negativa) en el dataset.
$$ P(c) = \frac{\text{Documentos en la clase } c}{\text{Total de documentos}} $$

**2. C√°lculo de Probabilidades Condicionales (Likelihoods) $P(w|c)$:**
Calcula la probabilidad de que una palabra $w$ aparezca, dado que pertenece a una clase $c$.

*
